// Test program to compare extracted kernels with spconv Python results
#include <cuda_runtime.h>
#include <iostream>
#include <vector>
#include <cstdlib>
#include <cmath>
#include <fstream>
#include <string>
#include "/tmp/json.hpp"

using json = nlohmann::json;

// Simple replacements for TensorView dependencies
namespace tv {
    template<typename T>
    struct KernelLoopX {
        int total;
        __device__ KernelLoopX(int size) : total(size) {}

        struct Iterator {
            int idx;
            int step;
            int total;

            __device__ Iterator(int start, int s, int t) : idx(start), step(s), total(t) {}
            __device__ Iterator& operator++() { idx += step; return *this; }
            __device__ int operator*() const { return idx; }
            __device__ bool operator!=(const Iterator& other) const { return idx < total; }
        };

        __device__ Iterator begin() const {
            return Iterator(blockIdx.x * blockDim.x + threadIdx.x, gridDim.x * blockDim.x, total);
        }
        __device__ Iterator end() const { return Iterator(total, 0, total); }
    };
}

// Include extracted kernels
template<typename T>
__global__ void gather_features_kernel(
    T* out_features,
    const T* in_features,
    const int* indices,
    int num_indices,
    int num_features
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < num_indices) {
        int in_idx = indices[idx];
        if (in_idx >= 0) {  // Valid index check
            // Copy all features for this point
            for (int f = 0; f < num_features; f++) {
                out_features[idx * num_features + f] =
                    in_features[in_idx * num_features + f];
            }
        } else {
            // Zero out if invalid index
            for (int f = 0; f < num_features; f++) {
                out_features[idx * num_features + f] = T(0);
            }
        }
    }
}

template<typename T>
__global__ void scatter_add_kernel(
    T* out_features,
    const T* in_features,
    const int* indices,
    int num_indices,
    int num_features
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int feature_idx = blockIdx.y * blockDim.y + threadIdx.y;

    if (idx < num_indices && feature_idx < num_features) {
        int out_idx = indices[idx];
        if (out_idx >= 0) {
            T value = in_features[idx * num_features + feature_idx];
            atomicAdd(&out_features[out_idx * num_features + feature_idx], value);
        }
    }
}

// Error checking macro
#define CHECK_CUDA(call) do { \
    cudaError_t error = call; \
    if (error != cudaSuccess) { \
        std::cerr << "CUDA error at " << __FILE__ << ":" << __LINE__ \
                  << " - " << cudaGetErrorString(error) << std::endl; \
        exit(1); \
    } \
} while(0)

// Load binary data from file
template<typename T>
std::vector<T> load_binary_file(const std::string& filename) {
    std::ifstream file(filename, std::ios::binary | std::ios::ate);
    if (!file.is_open()) {
        throw std::runtime_error("Failed to open file: " + filename);
    }

    size_t fileSize = file.tellg();
    size_t numElements = fileSize / sizeof(T);
    std::vector<T> data(numElements);

    file.seekg(0);
    file.read(reinterpret_cast<char*>(data.data()), fileSize);
    file.close();

    return data;
}

// Load metadata from JSON file
json load_metadata(const std::string& filename) {
    std::ifstream file(filename);
    json metadata;
    file >> metadata;
    return metadata;
}

// Compare two arrays with tolerance
template<typename T>
bool compare_arrays(const T* expected, const T* actual, size_t size,
                    float tolerance = 1e-5, int max_errors = 10) {
    int errors = 0;
    double max_diff = 0.0;
    double total_diff = 0.0;

    for (size_t i = 0; i < size; i++) {
        double diff = std::abs(static_cast<double>(expected[i]) - static_cast<double>(actual[i]));
        total_diff += diff;
        max_diff = std::max(max_diff, diff);

        if (diff > tolerance) {
            if (errors < max_errors) {
                std::cerr << "Mismatch at index " << i << ": expected " << expected[i]
                          << ", got " << actual[i] << " (diff: " << diff << ")" << std::endl;
            }
            errors++;
        }
    }

    double avg_diff = total_diff / size;
    std::cout << "Comparison stats - Max diff: " << max_diff
              << ", Avg diff: " << avg_diff
              << ", Errors: " << errors << "/" << size << std::endl;

    return errors == 0;
}

void test_gather_kernel_with_spconv() {
    std::cout << "\n=== Testing Gather Kernel vs SPConv ===" << std::endl;

    // Load test data generated by Python spconv
    auto input_features = load_binary_file<float>("test_data/gather_input_features.bin");
    // Note: indices are saved as float32 in the binary file due to numpy conversion
    auto indices_float = load_binary_file<float>("test_data/gather_indices.bin");
    auto expected_output = load_binary_file<float>("test_data/gather_output_features.bin");

    // Load metadata
    auto input_meta = load_metadata("test_data/gather_input_features.meta.json");
    auto output_meta = load_metadata("test_data/gather_output_features.meta.json");

    int num_total = input_meta["shape"][0];
    int num_features = input_meta["shape"][1];
    int num_active = output_meta["shape"][0];

    std::cout << "Input shape: [" << num_total << ", " << num_features << "]" << std::endl;
    std::cout << "Output shape: [" << num_active << ", " << num_features << "]" << std::endl;

    // Convert float indices to int32
    std::vector<int> indices_int32(indices_float.size());
    for (size_t i = 0; i < indices_float.size(); i++) {
        indices_int32[i] = static_cast<int>(indices_float[i]);
    }
    std::cout << "First 5 indices: ";
    for (int i = 0; i < std::min(5, (int)indices_int32.size()); i++) {
        std::cout << indices_int32[i] << " ";
    }
    std::cout << std::endl;

    // Allocate GPU memory
    float *d_input, *d_output;
    int *d_indices;

    CHECK_CUDA(cudaMalloc(&d_input, input_features.size() * sizeof(float)));
    CHECK_CUDA(cudaMalloc(&d_output, expected_output.size() * sizeof(float)));
    CHECK_CUDA(cudaMalloc(&d_indices, indices_int32.size() * sizeof(int)));

    CHECK_CUDA(cudaMemcpy(d_input, input_features.data(),
                          input_features.size() * sizeof(float), cudaMemcpyHostToDevice));
    CHECK_CUDA(cudaMemcpy(d_indices, indices_int32.data(),
                          indices_int32.size() * sizeof(int), cudaMemcpyHostToDevice));

    // Initialize output to zero first
    CHECK_CUDA(cudaMemset(d_output, 0, expected_output.size() * sizeof(float)));

    // Launch our extracted kernel
    dim3 threadsPerBlock(256);
    dim3 blocksPerGrid((num_active + threadsPerBlock.x - 1) / threadsPerBlock.x);

    std::cout << "Launching kernel with grid: " << blocksPerGrid.x
              << " and block: " << threadsPerBlock.x << std::endl;

    gather_features_kernel<<<blocksPerGrid, threadsPerBlock>>>(
        d_output, d_input, d_indices, num_active, num_features);

    CHECK_CUDA(cudaGetLastError());
    CHECK_CUDA(cudaDeviceSynchronize());

    // Copy result back
    std::vector<float> actual_output(expected_output.size());
    CHECK_CUDA(cudaMemcpy(actual_output.data(), d_output,
                          actual_output.size() * sizeof(float), cudaMemcpyDeviceToHost));

    // Compare with expected output
    bool passed = compare_arrays(expected_output.data(), actual_output.data(),
                                 expected_output.size(), 1e-5);

    if (passed) {
        std::cout << "✓ Gather kernel matches SPConv output!" << std::endl;
    } else {
        std::cout << "✗ Gather kernel does NOT match SPConv output!" << std::endl;
    }

    CHECK_CUDA(cudaFree(d_input));
    CHECK_CUDA(cudaFree(d_output));
    CHECK_CUDA(cudaFree(d_indices));
}

void test_scatter_kernel_with_spconv() {
    std::cout << "\n=== Testing Scatter Kernel vs SPConv ===" << std::endl;

    // Load test data
    auto input_features = load_binary_file<float>("test_data/scatter_input_features.bin");
    auto indices_float = load_binary_file<float>("test_data/scatter_indices.bin");
    auto expected_output = load_binary_file<float>("test_data/scatter_output_features.bin");

    // Load metadata
    auto input_meta = load_metadata("test_data/scatter_input_features.meta.json");
    auto output_meta = load_metadata("test_data/scatter_output_features.meta.json");

    int num_active = input_meta["shape"][0];
    int num_features = input_meta["shape"][1];
    int num_total = output_meta["shape"][0];

    std::cout << "Input shape: [" << num_active << ", " << num_features << "]" << std::endl;
    std::cout << "Output shape: [" << num_total << ", " << num_features << "]" << std::endl;

    // Convert float indices to int32
    std::vector<int> indices_int32(indices_float.size());
    for (size_t i = 0; i < indices_float.size(); i++) {
        indices_int32[i] = static_cast<int>(indices_float[i]);
    }

    // Allocate GPU memory
    float *d_input, *d_output;
    int *d_indices;

    CHECK_CUDA(cudaMalloc(&d_input, input_features.size() * sizeof(float)));
    CHECK_CUDA(cudaMalloc(&d_output, expected_output.size() * sizeof(float)));
    CHECK_CUDA(cudaMalloc(&d_indices, indices_int32.size() * sizeof(int)));

    CHECK_CUDA(cudaMemcpy(d_input, input_features.data(),
                          input_features.size() * sizeof(float), cudaMemcpyHostToDevice));
    CHECK_CUDA(cudaMemcpy(d_indices, indices_int32.data(),
                          indices_int32.size() * sizeof(int), cudaMemcpyHostToDevice));

    // Initialize output to zero
    CHECK_CUDA(cudaMemset(d_output, 0, expected_output.size() * sizeof(float)));

    // Launch kernel
    dim3 threadsPerBlock(16, 16);
    dim3 blocksPerGrid((num_active + threadsPerBlock.x - 1) / threadsPerBlock.x,
                       (num_features + threadsPerBlock.y - 1) / threadsPerBlock.y);

    scatter_add_kernel<<<blocksPerGrid, threadsPerBlock>>>(
        d_output, d_input, d_indices, num_active, num_features);

    CHECK_CUDA(cudaGetLastError());
    CHECK_CUDA(cudaDeviceSynchronize());

    // Copy result back
    std::vector<float> actual_output(expected_output.size());
    CHECK_CUDA(cudaMemcpy(actual_output.data(), d_output,
                          actual_output.size() * sizeof(float), cudaMemcpyDeviceToHost));

    // Compare with expected output
    bool passed = compare_arrays(expected_output.data(), actual_output.data(),
                                 expected_output.size(), 1e-5);

    if (passed) {
        std::cout << "✓ Scatter kernel matches SPConv output!" << std::endl;
    } else {
        std::cout << "✗ Scatter kernel does NOT match SPConv output!" << std::endl;
    }

    CHECK_CUDA(cudaFree(d_input));
    CHECK_CUDA(cudaFree(d_output));
    CHECK_CUDA(cudaFree(d_indices));
}

int main() {
    std::cout << "=== Comparing Extracted Kernels with SPConv Python API ===" << std::endl;
    std::cout << "This test loads data generated by spconv Python and compares results" << std::endl;

    // Check CUDA device
    int deviceCount = 0;
    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));

    if (deviceCount == 0) {
        std::cerr << "No CUDA devices found!" << std::endl;
        return 1;
    }

    cudaDeviceProp prop;
    CHECK_CUDA(cudaGetDeviceProperties(&prop, 0));
    std::cout << "Using device: " << prop.name << std::endl;
    std::cout << "Compute capability: " << prop.major << "." << prop.minor << std::endl;

    // Run comparison tests
    test_gather_kernel_with_spconv();
    test_scatter_kernel_with_spconv();

    std::cout << "\n=== Comparison tests completed ===" << std::endl;
    std::cout << "Note: Full sparse convolution comparison requires implementing" << std::endl;
    std::cout << "      index generation and implicit GEMM, which is more complex." << std::endl;

    return 0;
}